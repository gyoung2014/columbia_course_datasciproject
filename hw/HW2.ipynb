{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E6998 â€“ HW2 Solution\n",
    "### Student Columbia Uni: yg2499\n",
    "\n",
    "#### Note: The code is running under Python 3.x version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step A: Train a model to classify the same topics from class: fishing, hiking, machinelearning and mathematics using the train.py script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction\n",
    "from scipy import stats\n",
    "from sklearn import decomposition,linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier,Lasso,SGDClassifier,LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,hamming_loss\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score,precision_recall_curve,f1_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import sklearn\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn import decomposition\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "#from multiscorer import MultiScorer\n",
    "import seaborn\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from bson import json_util\n",
    "from bson.json_util import dumps\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thePath = '/Users/gyang/Desktop/ProjectDataScience/data/classify/'\n",
    "\n",
    "#thePathLut = '/Users/gyang/Desktop/ProjectDataScience/code/'\n",
    "theCols = os.walk(thePath).__next__()[1]  #use __next__() in py3.x instead of next() in python 2.x\n",
    " \n",
    "theLabels = theCols \n",
    "\n",
    "finalWords = list()\n",
    "theDocs = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this part of code referred by week 3 in class exercise\n",
    "#no modified\n",
    "\n",
    "def genCorpus(theText):\n",
    "    #set dictionaries\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    theStemmer = nltk.stem.porter.PorterStemmer() #Martin Porters celebrated stemming algorithm\n",
    "    \n",
    "    #pre-processing\n",
    "    theText = theText.split()\n",
    "    tokens = [token.lower() for token in theText] #ensure everything is lower case\n",
    "    tokens = [re.sub(r'[^a-zA-Z]+', ' ',token) for token in tokens] #remove special characters but leave word in tact\n",
    "    tokens = [token for token in tokens if token.lower().isalpha()] #ensure everything is a letter\n",
    "    tokens = [word for word in tokens if word not in stopWords] #rid of stop words\n",
    "    tokens = [theStemmer.stem(word) for word in tokens] #stem words uing porter stemming algorithm\n",
    "    tokens = \" \".join(tokens) #need to pass string seperated by spaces       \n",
    "\n",
    "    return tokens\n",
    "\n",
    "def textToNum(theLabels,thePredLabel):\n",
    "    theOutLabel = dict()\n",
    "    cnt = 0\n",
    "    for word in theLabels:\n",
    "        theOutLabel[word] = cnt\n",
    "        cnt = cnt + 1\n",
    "    return str(theOutLabel[thePredLabel])\n",
    "\n",
    "for word in theCols:\n",
    "    cnt = 0\n",
    "    for file in os.listdir(thePath+word):\n",
    "        if file.endswith('.txt'):\n",
    "            try:\n",
    "                f = open(thePath + word + \"/\" + file, \"r\")\n",
    "                lines = f.readlines()\n",
    "                lines = [text.strip() for text in lines]\n",
    "                lines = \" \".join(lines)\n",
    "                finalWords.append(genCorpus(lines))\n",
    "                theDocs.append(textToNum(theLabels,word) +\"_\" + str(cnt))\n",
    "                cnt = cnt +  1\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features =1000,ngram_range =(1,1))\n",
    "tdm = pd.DataFrame(vectorizer.fit_transform(finalWords).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035972</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1    2         3    4    5         6    7         8        9    \\\n",
       "0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0  0.035972  0.00000   \n",
       "1  0.0  0.000000  0.0  0.023988  0.0  0.0  0.000000  0.0  0.000000  0.00000   \n",
       "2  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.00000   \n",
       "3  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.01908   \n",
       "4  0.0  0.028741  0.0  0.000000  0.0  0.0  0.075636  0.0  0.000000  0.00000   \n",
       "\n",
       "     ...     990  991  992       993  994  995      996  997  998       999  \n",
       "0    ...     0.0  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  0.000000  \n",
       "1    ...     0.0  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  0.136701  \n",
       "2    ...     0.0  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  0.000000  \n",
       "3    ...     0.0  0.0  0.0  0.039982  0.0  0.0  0.02672  0.0  0.0  0.000000  \n",
       "4    ...     0.0  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  0.026406  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdm.columns= vectorizer.get_feature_names()\n",
    "tdm.index=theDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=.95)\n",
    "pca.fit(tdm)\n",
    "reducedTDM = pd.DataFrame(pca.transform(tdm)) #reduced tdm distance matrix - features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reducedTDM.index=theDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcaVar = round(sum(pca.explained_variance_ratio_),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels\n",
    "fullIndex = reducedTDM.index.values\n",
    "fullIndex = [int(word.split(\"_\")[0]) for word in fullIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build models\n",
    "lr = LogisticRegression() #logistic regression\n",
    "svm = LinearSVC() #SVM\n",
    "rfc = RandomForestClassifier() #random forest\n",
    "dtc = DecisionTreeClassifier(max_depth=30) #decision tree\n",
    "abdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),learning_rate=1,algorithm=\"SAMME\",n_estimators=300) #ABDT\n",
    "knn = KNeighborsClassifier() #KNN\n",
    "bag = BaggingClassifier(bootstrap =True) #bagging\n",
    "nn = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(15,), random_state=1,alpha=1e-5) #Multi-layer Perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "lr_scores = cross_val_score(lr, reducedTDM,fullIndex, cv=10)\n",
    "svm_scores = cross_val_score(svm, reducedTDM,fullIndex, cv=10)\n",
    "rfc_scores = cross_val_score(rfc, reducedTDM,fullIndex, cv=10)\n",
    "dtc_scores = cross_val_score(dtc, reducedTDM,fullIndex, cv=10)\n",
    "abdt_scores = cross_val_score(abdt, reducedTDM,fullIndex, cv=10)\n",
    "knn_scores = cross_val_score(knn, reducedTDM,fullIndex, cv=10)\n",
    "bag_scores = cross_val_score(bag, reducedTDM,fullIndex, cv=10)\n",
    "nn_scores = cross_val_score(nn, reducedTDM,fullIndex, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losgistic Regression Accuracy: 0.97307692\n",
      "SVM Accuracy: 0.95384615\n",
      "Random Forest Accuracy: 0.88443732\n",
      "Decision Tree Accuracy: 0.95384615\n",
      "Ada Boost Decision Tree Accuracy: 0.88461538\n",
      "KNN Accuracy: 0.96153846\n",
      "Bagging Accuracy: 0.97307692\n",
      "Multi-layer Perceptron Accuracy: 0.97307692\n"
     ]
    }
   ],
   "source": [
    "print(\"Losgistic Regression Accuracy: %0.8f\" % (lr_scores.mean()))\n",
    "print(\"SVM Accuracy: %0.8f\" % (svm_scores.mean()))\n",
    "print(\"Random Forest Accuracy: %0.8f\" % (rfc_scores.mean()))\n",
    "print(\"Decision Tree Accuracy: %0.8f\" % (dtc_scores.mean()))\n",
    "print(\"Ada Boost Decision Tree Accuracy: %0.8f\" % (abdt_scores.mean()))\n",
    "print(\"KNN Accuracy: %0.8f\" % (knn_scores.mean()))\n",
    "print(\"Bagging Accuracy: %0.8f\" % (bag_scores.mean()))\n",
    "print(\"Multi-layer Perceptron Accuracy: %0.8f\" % (nn_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grid search parameters tuning\n",
    "lr_grid =GridSearchCV(estimator=lr, param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] })\n",
    "svm_grid = GridSearchCV(estimator=svm,param_grid={\"C\":[1,0.1,0.05,0.01,0.005]})\n",
    "rfc_grid =GridSearchCV(estimator=rfc, param_grid={\"n_estimators\": [10,30,50,100]})\n",
    "dtc_grid =GridSearchCV(estimator=dtc, param_grid={\"max_depth\": [10,30,50,100]})\n",
    "abdt_grid =GridSearchCV(estimator=abdt, param_grid={\"n_estimators\": [10,30,50,100,200,300]})\n",
    "knn_grid =GridSearchCV(estimator=knn,param_grid = dict(n_neighbors=range(1,6)))\n",
    "bag_grid =GridSearchCV(estimator=bag, param_grid={\"n_estimators\": [10,30,50,100]})\n",
    "nn_grid =GridSearchCV(estimator=nn, param_grid={\"alpha\": [1,0.1,0.01,0.001,0.0001,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_fit =lr_grid.fit(reducedTDM,fullIndex)\n",
    "svm_fit =svm_grid.fit(reducedTDM,fullIndex)\n",
    "rfc_fit =rfc_grid.fit(reducedTDM,fullIndex)\n",
    "dtc_fit =dtc_grid.fit(reducedTDM,fullIndex)\n",
    "abdt_fit =abdt_grid.fit(reducedTDM,fullIndex)\n",
    "knn_fit =knn_grid.fit(reducedTDM,fullIndex)\n",
    "bag_fit =bag_grid.fit(reducedTDM,fullIndex)\n",
    "nn_fit =nn_grid.fit(reducedTDM,fullIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bestscore(grid):\n",
    "    bestScore = round(grid.best_score_,4)\n",
    "    parameters = grid.best_params_\n",
    "    return (bestScore,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_bestscores =bestscore(lr_fit)\n",
    "svm_bestscores =bestscore(svm_fit)\n",
    "rfc_bestscores =bestscore(rfc_fit)\n",
    "dtc_bestscores =bestscore(dtc_fit)\n",
    "abdt_bestscores =bestscore(abdt_fit)\n",
    "knn_bestscores =bestscore(knn_fit)\n",
    "bag_bestscores =bestscore(bag_fit)\n",
    "nn_bestscores =bestscore(nn_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR --> Best Score: 0.9691 and Parameters: {'C': 1}\n",
      "SVM --> Best Score: 0.973 and Parameters: {'C': 0.05}\n",
      "Random Forest --> Best Score: 0.9537 and Parameters: {'n_estimators': 100}\n",
      "Decision Tree --> Best Score: 0.9653 and Parameters: {'max_depth': 100}\n",
      "ABDT --> Best Score: 0.4826 and Parameters: {'n_estimators': 10}\n",
      "KNN --> Best Score: 0.9653 and Parameters: {'n_neighbors': 5}\n",
      "Bagging --> Best Score: 0.973 and Parameters: {'n_estimators': 30}\n",
      "NN --> Best Score: 0.9614 and Parameters: {'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "print(\"LR --> Best Score: \" + str(lr_bestscores[0]) + \" and Parameters: \" + str(lr_bestscores[1]))\n",
    "print(\"SVM --> Best Score: \" + str(svm_bestscores[0]) + \" and Parameters: \" + str(svm_bestscores[1]))\n",
    "print(\"Random Forest --> Best Score: \" + str(rfc_bestscores[0]) + \" and Parameters: \" + str(rfc_bestscores[1]))\n",
    "print(\"Decision Tree --> Best Score: \" + str(dtc_bestscores[0]) + \" and Parameters: \" + str(dtc_bestscores[1]))\n",
    "print(\"ABDT --> Best Score: \" + str(abdt_bestscores[0]) + \" and Parameters: \" + str(abdt_bestscores[1]))\n",
    "print(\"KNN --> Best Score: \" + str(knn_bestscores[0]) + \" and Parameters: \" + str(knn_bestscores[1]))\n",
    "print(\"Bagging --> Best Score: \" + str(bag_bestscores[0]) + \" and Parameters: \" + str(bag_bestscores[1]))\n",
    "print(\"NN --> Best Score: \" + str(nn_bestscores[0]) + \" and Parameters: \" + str(nn_bestscores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model pick up -- Bagging classifier\n",
    "bestmodel =BaggingClassifier(bootstrap =True,n_estimators =10)\n",
    "bestmodel.fit(reducedTDM,fullIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96538461538461529"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bestmodel, reducedTDM,fullIndex, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bestmodel.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save best model\n",
    "filename = 'bestmodel.pkl'\n",
    "joblib.dump(bestmodel, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test load the model from disk\n",
    "best_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step B: Embed the trained model from above into the twitter streaming engine class, StreamListener.  25-points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy  \n",
    "from pymongo import MongoClient\n",
    "from textwrap import TextWrapper\n",
    "from tweepy.utils import import_simplejson\n",
    "json = import_simplejson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StreamListener(tweepy.StreamListener):  \n",
    "    status_wrapper = TextWrapper(width=140, initial_indent='', subsequent_indent='')    \n",
    "    def on_status(self, status): \n",
    "        tempA = self.status_wrapper.fill(status.text)\n",
    "        tempB = status.retweeted \n",
    "        tempC = status.user.lang \n",
    "        tempD = status.geo\n",
    "        \n",
    "        ############################################################\n",
    "        #embed code here\n",
    "        \n",
    "        testText = list()\n",
    "        testText.append(genCorpus(self.status_wrapper.fill(status.text)))\n",
    "        test = vectorizer.transform(testText)\n",
    "        X2_new = pca.transform(test.toarray())\n",
    "        x = best_model.predict(X2_new)\n",
    "        pred_label =theCols[int(x)]\n",
    "        \n",
    "        \n",
    "        ############################################################\n",
    "        \n",
    "        if (((\"en\" in tempC) and (tempB is False)) and (not(\"RT\") in tempA[:2]) and ((((\"http\" or \"www\") in tempA) and ((' ') in tempA)) or (not(\"http\" or \"www\") in tempA))):\n",
    "        #TO DO\n",
    "            \n",
    "        #tempA is text body\n",
    "            try:     \n",
    "                print(self.status_wrapper.fill(status.text))\n",
    "                mongo_collection.insert({\n",
    "                'body': self.status_wrapper.fill(status.text),\n",
    "                'topic': pred_label,\n",
    "                'message_id': status.id,\n",
    "                'screen_name': status.author.screen_name,\n",
    "                'created_at': status.created_at,\n",
    "                'followers': status.user.followers_count,\n",
    "                'friends_count': status.user.friends_count,\n",
    "                'location': status.user.location\n",
    "                })\n",
    "            except Exception as e:  \n",
    "            #print(\"HERE\")          \n",
    "                pass \n",
    "        \n",
    "#print(\"here\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step C: Using your twitter application credentials, perform real-time classification on tweets (~100) that have the following regex set in setTerms and save results to a mongo database/collection: 40-points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "auth1 = tweepy.auth.OAuthHandler('wNaJv1v48TSxgwS5nsDczvHFt',\n",
    "                                 'f9YAbBkNtA6aRX5TmVQRZNi7QsSMVz9xjedaleTFNAqIQ4w6Co')  \n",
    "auth1.set_access_token('915367239733383168-BRMk1IVhls8HjQTZlErdvKpW8m5prPR',\n",
    "                       'GinBjBKVkP8lqjkfEtfaDKczgawna3yvQ0X6ydGm04w52')  \n",
    "api = tweepy.API(auth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo = MongoClient('localhost', 27017)\n",
    "mongo_db = mongo['twitterDB3s']\n",
    "mongo_collection = mongo_db['theData']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Just Use \"Stop\" to stop running kernel,otherwise it will continue running ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@tupatsfan Russell fishing for triple double. Teammates being used to throwing out a rebound to give him an assist opportunity. ðŸ™„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyang/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BASS_nation The weather is perfect. Should be fishing. Full plate.....shucks!\n",
      "You know what? It's fine if you just want attention. Looking for sympathy? Ego boost? Fuck'em, go fishing! I'll bite.\n",
      "Mens Columbia \"Gray Ridge\" Titanium Fleece Jacket XXL at Tactical Gear Zone -&gt; https://t.co/9KPWhnyapn #columbia #hiking #deals #shopping\n",
      "â€¦\n",
      "The BBC will use machine learning to improve programming https://t.co/HDd1dX89Fv\n",
      "#NewYork #SusquehannaRiver #FlyFishing Report https://t.co/Y4uHagHpLb #NewYorkCity #Buffalo #Rochester #fishing #montanalife #tenkarausa\n",
      "Guess Arrieta is gonna have to visit Trump at the White House on his own time. Cubs gone fishing.\n",
      "2017 New Good Quality fishing lure Minnow 70mm/6g 0.5-1 Mt Dive Artificial Ba ... https://t.co/7Xvkm6EzuB https://t.co/R2xGbdyc95\n",
      "I took this photograph during my visit to Vinh Hy, a fishing village in Vietnam, in July,2014. If you ever travel... https://t.co/CDUs80E7Is\n",
      "SssnakePit_Lets keep it Real...Itz been a Good Run...Thank U @Cubs for getting as far as U did...Time to go Fishing. https://t.co/5dY88gKICA\n",
      "â˜  P.I. Buck McDivit inherits a ramshackle fishing lodge #paranormal #action #adventure #FridayReads https://t.co/DeuSyKUvu5\n",
      "#fishing - https://t.co/mI4sYD4FlY - SLOW JIG LOVE Part One! https://t.co/M4CnCG3ytS\n",
      "Some damn hiking shoes https://t.co/oCMD2sPghk\n",
      "Bass Fishing Off the Bank | NEW LURES &amp;Â TIPS https://t.co/oqYoGnddsG https://t.co/6FAOFMX6hq\n",
      "https://t.co/ekkigjVrES  This makes me so sad ðŸ˜¿ I used to work with him, he was so funny &amp; such a character always had a smile on his\n",
      "face\n",
      "@beachcrazy70 @par995 @kathy_mccallum @stacey_macgowan @newenglandgrl @Tina_Bradley27 @pratt_rosalyn @frenchcat369â€¦ https://t.co/fCBDwT62iE\n",
      "Hell yea that was a jab at how poorly American schools teach science and mathematics\n",
      "#TBT to #hiking the #Tongariro Alpine Crossing in #NewZealand. Our apparel is inspired by adventures just like thisâ€¦ https://t.co/1w0Wmc3OeQ\n",
      "HIKING IN BEAUTÄ°FUL UTTAH NATIONAL PARK. https://t.co/tDoaxcgIzZ\n",
      "&lt;p&gt;Sonora getaway: hiking trails, Indigeny Reserve ciderworks&lt;/p&gt; https://t.co/HUe8QyF891\n",
      "2 Pack Merino Wool Menâ€™s Hiking Socks #fashion #free #shop #style #sales #today #love #giveaway inâ€¦ https://t.co/edoQsx8ujT\n",
      "2 Pack Merino Wool Menâ€™s Hiking Socks #fashion #free #shop #style #sales #today #love #giveaway inâ€¦ https://t.co/ZC7GtUDmxm\n",
      "For legal chatbots that ask open-ended ?s, it is like lawyers taking depositions. ðŸ‘ for fishing, but ðŸ‘Ž if lacking knowledge of it all /3\n",
      "Flounder fishing tips that really work! https://t.co/zdNX3E4QMd\n",
      "Where the Mississippi River empties into the gulf of Mexico offers great fishing! https://t.co/5DQv68oc6l RT @On_Target_\n",
      "Shirts are not just shirts&gt; Performance fishing shirts for great charter adventures https://t.co/zQXCfNXMnG RT @Travels_Charley\n",
      "@DaintyVelocity &gt; through his brunette locks.   Little did he know, his day was about to get interestingâ€¦  With hisâ€¦\n",
      "https://t.co/4igjNuRr4e\n",
      "Keep hiking kids entertained with Leaf Match https://t.co/LImNOWer61 #nevertooyoungtohike #hikeitbaby #bornwild\n",
      "#Pennsylvania #PleasantStream #FlyFishing Report https://t.co/X0aM7ZpMw1 #Philadelphia #Pittsburgh #Allentown #fishing #flytying #lake #USA\n",
      "Slow week for fishing in the Manning https://t.co/B23IomnQoC\n",
      "#Fishing from Boat #Personalised Print #GorgeousGift made with YOUR words https://t.co/dkhn9tnOmN #QueenOfâ€¦ https://t.co/fgEDHYY9Js\n",
      "Corky Lures: The Legendary Saltwater Fishing Lure from Texas https://t.co/n0KjODH4Gs\n",
      "Role Of #Machine Learning And AI In #HealthcareÂ #Cybersecurity https://t.co/w73uy7Q5GK https://t.co/hIxCflYST9\n",
      "@LivingOnChi There are soo many things wrong with our oceans.  Over Fishing too warm too polluted too much plasticâ€¦ https://t.co/Rij8oEoUfA\n",
      "Role Of #Machine Learning And AI In #HealthcareÂ #Cybersecurity https://t.co/auA3m8sPCv https://t.co/XcUDpw78yP\n",
      "#NewYork #ShekomekoCreek #FlyFishing Report https://t.co/dr5o6XnAId #NewYorkCity #Buffalo #Rochester #fishing #RioProducts #anglers #weather\n",
      "@saamcardosoo @JimBlueJay99 @timkellernyc Sure. But odd for TK to throw out an eye catching tweet that challenges tâ€¦ https://t.co/1apIbkNsJR\n",
      "@DaintyVelocity &gt; something within the water, an excited look sparking within his hazel eyes, he began to twist theâ€¦\n",
      "https://t.co/RYx5dMer5m\n",
      "Lecturer in Mathematics or Statistics (Bendigo) - The Conversation AU https://t.co/7Pgk0yFm2y\n",
      "Lecturer in Mathematics or Statistics (Bendigo) - The Conversation AU https://t.co/DIdBu7X6dD\n",
      "Hiking the Great Wall of Seongnam, South Korea https://t.co/OmWxdwbnGk #Travel\n",
      "Amazing kids fishing video catch a lot of fish by hand - Traditional fishing video in cambodia: https://t.co/FzcainYMZJ via @YouTube\n",
      "Lake Forecast: Leech Lake, Clear, 59 Degrees, High: 69, Low 46, Wind Speed 9.0 mph, B.Pressure 29.8 inches. #fishing\n",
      "HOW TO RIG ZOOM LIZARDS FOR BASS! HOW TO FISH ZOOM LIZARDS! NEW ENGLAND BASSÂ FISHING! https://t.co/r4noAijy0Z https://t.co/8LMihLGW3z\n",
      "GONE FISHING taking a break from all the disturbingly news media https://t.co/uPjqlAGH9r\n",
      "My first time experience with hiking, thanks to my little bro https://t.co/Qm32vx6RAG\n",
      "Mens Columbia \"Gray Ridge\" Titanium Fleece Jacket XXL at Tactical Gear Zone -&gt; https://t.co/HtxfAje6Td #columbia #hiking #deals #shopping\n",
      "â€¦\n",
      "Linesider is a new Striped Bass Tee by #GuyHarvey avail at https://t.co/PBUmRq5sb8 RT 4 Bass Fishing https://t.co/TKlqUmMVa9\n",
      ".@HumboldtToiyabe .@forestservice Fall Getaway #LasVegas #Outdoors #Hiking #Nature https://t.co/QOiNdG2LD9\n",
      "#Arizona #NankoweapCreek #FlyFishing Report https://t.co/Jm6MT0invV #Phoenix #Tucson #Mesa #fishing #montanalife #Waterworks-Lamson #USA\n",
      "@Angeles_NF Which hiking trails are affected? ðŸ˜¢\n",
      "@WesleySliva18 Fishing trip?ðŸ¤”\n",
      "Haha  ðŸŸ v ðŸ®  Tag a mate that loves fishing but is a steak lover at heart â¤ï¸ ðŸ´ https://t.co/eeh6qEyD15\n",
      "@rahulkanwal While Pollution concerns all of us, where and how did you end up with 24X. What base denominator are yâ€¦ https://t.co/Wd7jPS1jnf\n",
      "Hereâ€™s some interesting #MachineLearning #news &amp; #information from a trusted industry source brought to you byâ€¦ https://t.co/RhteGqXEXm\n",
      "I added a video to a @YouTube playlist https://t.co/GCbyZtyVuj Forest Park Portland, Oregon Vlog 009 Hike - 2017 Hiking Around the\n",
      "#Montana #MiddleForkDearbornRiver #FlyFishing Report https://t.co/nEsH8RIgx4 #Billings #Missoula #GreatFalls #fishing #patagonia #travel\n",
      "Need power to reach skinny water fishing destinations? https://t.co/VIgUrTm5VQ RT @Grapechick\n",
      "These boys are in #fishing ðŸŽ£ #hunting heaven ðŸ˜ðŸ’— https://t.co/grhMWK9cko\n",
      "Queensland introduces GPS trackers for all commercial fishermen to track catch https://t.co/RlujyJ2Eel\n",
      "#NorthCarolina #ScottCreek #FlyFishing Report https://t.co/PQ1Cm30eNl #Charlotte #Raleigh #Greensboro #fishing #patagonia #sciAnglers #bass\n",
      "10:23pm Otter Tail Lake current temp 55F feels like 53F humidity 63% wind S 8 mph. Fishing forecast at https://t.co/5qiRxAXnWc\n",
      "The latest The Fishing Gear Daily! https://t.co/odvEjpfxDI Thanks to @MeghalayaMagazi\n",
      "https://t.co/XjFUemVHSj |   500M LineThink A-Factor Premium Quality Nylon Mon ... https://t.co/Uu2E1rJeS9 https://t.co/9QpJdkCgmL\n",
      "Hereâ€™s some interesting #AI #news &amp; #information from a trusted industry source brought to you by @TheIoTWarehouse:\n",
      "https://t.co/mh4RtvGxUT\n",
      "LivingOnChi: RT marzhanel: LivingOnChi There are soo many things wrong with our oceans.  Over Fishing too warm tooâ€¦ https://t.co/QTK7xRGTDQ\n",
      "Know the Difference Between AI, Machine Learning, and Deep Learning https://t.co/WhdSH4cAfn via @https://twitter.com/edgylabsdotcom\n",
      "Ugh I seriously wanna go hiking soooo bad\n",
      "Good luck to all of the Juniors from around the world fishing at @wraysburylake this weekend in the @WCCUK Junior eâ€¦ https://t.co/mynlMmjdg2\n",
      "The latest Machine Learning Daily! https://t.co/mDdIddro2T Thanks to @TechnicallyBMR @debwalery @ChristophKae #machinelearning #ai\n",
      "Need a workhorse boat for inshore fishing?Â  This is it! https://t.co/rAlfRsugw9\n",
      "[SC] \"Hacker. Might go fishing after.\"  No picture accompanied it, as the conversation was over for him. He just waâ€¦ https://t.co/EHkhN9sLS6\n",
      "#Pennsylvania #BaldEagleCreek #FlyFishing Report https://t.co/IbMFmcA4qu #Philadelphia #Pittsburgh #Allentown #fishing #buffusa #travel #USA\n",
      "we dont study mathematics.  we study arithmancy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Pack Merino Wool Menâ€™s Hiking Socks #fashion #free #shop #style #sales #today #love #giveaway inâ€¦ https://t.co/3muh7c5glv\n",
      "Download Fish for Money and earn $15 gift cards just for playing a fishing game! @Apps_that_Pay https://t.co/DywKkQBRL8\n",
      "Stop fishing for compliments lol it ainâ€™t happening\n",
      "5 of these little guys this evening in about 30 minutes. Fishing has been tough lately so, forâ€¦ https://t.co/CEx8i8KmIC\n",
      "Amazing Girl Fishing em Siem Reap - Cambodia Traditional Fishing - Como pegar peixe (parte 4): https://t.co/kuRyoBiSe7 via @YouTube\n",
      "Amazing kids fishing video catch a lot of fish by hand - Traditional fis... https://t.co/etpHGJQ0bu via @YouTube\n",
      "we needa believe it when people say nature has been here before us and will be here after us, we ainâ€™t special https://t.co/fFixqiEZ9o\n",
      "Secrets to fishing a new lake for big bass from a Yamaha Pro! https://t.co/FfZx1EqsWq RT @Travels_Charley\n",
      "Great bass fishing insights &amp; advice from Yamaha Pro Ish Monroe https://t.co/nbslAMPrtc RT @Grapechick\n",
      "You can build the boat of your fishing dreams here! https://t.co/WUK8z09VQD RT @On_Target_\n",
      "I liked a @YouTube video https://t.co/g18DNNzAuR Tiger prawn fishing in the Northern prawn fishery- (NPF) 2016\n",
      "Game for drive to trail: Reverse Spelling Bee https://t.co/5fJNlz0cbh #hikeitbaby #hiking #familiesonfoot\n",
      "#Pennsylvania #PleasantStream #FlyFishing Report https://t.co/X0aM7ZpMw1 #Philadelphia #Pittsburgh #Allentown #fishing #news #water #lake\n",
      "An introduction to derivatives, calculation of derivatives of algebraic and trigonometric functions; applicationsâ€¦ https://t.co/6dnBBbcBS5\n",
      "RZA + Mathematics Break Down The New Album And Discuss Wu History https://t.co/l4LXiu81v6 via @YouTube\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1546\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-40fc9e6441c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstreamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msetTerms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"fishing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hiking\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"machine learning\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mathematics\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msetTerms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stream.twitter.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, async)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnooze_time_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;31m# This is still necessary, as a SSLError can actually be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_read_loop\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# keep-alive new lines are expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mread_line\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The read operation timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(socks, timeout)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0moptionally\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     sockets that can be read from immediately. \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wait_for_io_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_READ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36m_wait_for_io_events\u001b[0;34m(socks, events, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return [key[0].fileobj for key in\n\u001b[0;32m---> 26\u001b[0;31m                 selector.select(timeout) if key[1] & events]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             kevent_list = _syscall_wrapper(self._kqueue.control, True,\n\u001b[0;32m--> 513\u001b[0;31m                                            None, max_events, timeout)\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkevent_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gyang/anaconda/lib/python3.6/site-packages/requests/packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36m_syscall_wrapper\u001b[0;34m(func, _, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         and recalculate their timeouts. \"\"\"\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0merrcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l = StreamListener()  \n",
    "streamer = tweepy.Stream(auth=auth1, listener=l, timeout=3000)   \n",
    "setTerms = [\"fishing\",\"hiking\",\"machine learning\",\"mathematics\"]\n",
    "streamer.filter(track =setTerms,languages=['en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step D: Export your mongo collection from above to a json file called sample.json.  10-points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract json to local file\n",
    "#method 1\n",
    "c =mongo_collection.find({})\n",
    "\n",
    "with open('sample.json', 'w') as outfile:\n",
    "    for line in c:\n",
    "        json.dump(line,outfile,default =json_util.default)\n",
    "        outfile.write('\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method 2 \n",
    "#json.dump(json_util.dumps(mongo_collection.find({})), open(\"sample.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
